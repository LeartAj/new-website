<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Neural Network Optimization - Leart Ajvazaj</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <script src="https://www.desmos.com/api/v1.7/calculator.js?apikey=dcb31709b452b1cf9dc26972add0fda6"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        .article-container {
            max-width: 800px;
            margin: 120px auto 60px;
            padding: 0 20px;
        }
        
        .article-meta {
            margin-bottom: 2rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid #eee;
        }
        
        .article-date {
            color: #666;
            font-size: 0.9rem;
        }
        
        .article-category {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
            margin-left: 1rem;
        }
        
        .article-title {
            font-size: 2.5rem;
            font-weight: 700;
            color: #333;
            margin: 1rem 0;
            line-height: 1.3;
        }
        
        .article-subtitle {
            font-size: 1.2rem;
            color: #666;
            line-height: 1.6;
            margin-bottom: 2rem;
        }
        
        .article-content {
            font-size: 1.1rem;
            line-height: 1.8;
            color: #444;
        }
        
        .article-content h2 {
            font-size: 1.8rem;
            margin: 2.5rem 0 1.5rem;
            color: #333;
        }
        
        .article-content h3 {
            font-size: 1.4rem;
            margin: 2rem 0 1rem;
            color: #333;
        }
        
        .article-content p {
            margin-bottom: 1.5rem;
        }
        
        .article-content code {
            background: #f5f7ff;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        .article-content pre {
            background: #f5f7ff;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
        }
        
        .article-content pre code {
            background: none;
            padding: 0;
        }
        
        .article-content img {
            max-width: 100%;
            border-radius: 8px;
            margin: 2rem 0;
        }
        
        .article-figure {
            margin: 2.5rem 0;
        }
        
        .article-image {
            width: 100%;
            height: auto;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }
        
        .article-image:hover {
            transform: scale(1.01);
        }
        
        figcaption {
            margin-top: 1rem;
            text-align: center;
            color: #666;
            font-size: 0.9rem;
            font-style: italic;
        }
        
        /* Make sure images don't overflow on mobile */
        @media (max-width: 768px) {
            .article-figure {
                margin: 2rem 0;
            }
        }
        
        .article-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 1.5rem;
            margin: 2rem 0;
            font-style: italic;
            color: #555;
        }
        
        .article-footer {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid #eee;
        }
        
        .article-tags {
            display: flex;
            gap: 0.5rem;
            margin-bottom: 2rem;
        }
        
        .article-tag {
            background: #f0f0f0;
            color: #666;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
        }
        
        .article-share {
            display: flex;
            gap: 1rem;
        }
        
        .share-button {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: #667eea;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s ease;
        }
        
        .share-button:hover {
            color: #5a67d8;
        }
        
        .math {
            overflow-x: auto;
            margin: 1rem 0;
        }

        /* Interactive Graph Styles */
        .interactive-graph {
            margin: 2.5rem 0;
            border: 1px solid #e0e0e0;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        .graph-title {
            background: #f8f9ff;
            padding: 1rem 1.5rem;
            margin: 0;
            font-size: 1.1rem;
            font-weight: 600;
            color: #333;
            border-bottom: 1px solid #e0e0e0;
        }

        .graph-container {
            height: 400px;
            width: 100%;
            background: white;
        }

        .desmos-container {
            height: 500px;
        }

        .graph-description {
            padding: 1rem 1.5rem;
            background: #f8f9ff;
            font-size: 0.9rem;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        @media (max-width: 768px) {
            .graph-container {
                height: 300px;
            }
            .desmos-container {
                height: 400px;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <a href="index.html">Leart Ajvazaj</a>
            </div>
            <div class="nav-menu" id="nav-menu">
                <a href="index.html" class="nav-link">Home</a>
                <a href="writings.html" class="nav-link active">Writings</a>
                <a href="technical.html" class="nav-link">Technical</a>
                <a href="faq-recommendations.html" class="nav-link">Recommendations</a>
                <a href="write.html" class="nav-link">Write</a>
                <a href="index.html#about" class="nav-link">About</a>
            </div>
            <div class="language-toggle" id="language-toggle">
                <img src="https://flagcdn.com/w80/al.png" alt="Albanian Flag" class="flag-icon" title="Shqip">
            </div>
            <div class="hamburger" id="hamburger">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <article class="article-container">
        <div class="article-meta">
            <span class="article-date">March 15, 2024</span>
            <span class="article-category">Machine Learning</span>
            <h1 class="article-title">Understanding Neural Network Optimization: A Geometric Perspective</h1>
            <p class="article-subtitle">An exploration of the geometry of neural network loss landscapes and how it influences training dynamics</p>
        </div>

        <div class="article-content">
            <p>
                The optimization of neural networks remains one of the most fascinating challenges in machine learning. 
                While we've developed numerous techniques to train these models effectively, understanding why certain 
                approaches work better than others often requires delving into the geometric properties of the loss landscape.
            </p>

            <figure class="article-figure">
                <img src="/images/articles/image.png" alt="A majestic moose standing in a snowy landscape" class="article-image">
                <figcaption>Just like this majestic moose navigating through the wilderness, optimization algorithms must find their way through complex loss landscapes.</figcaption>
            </figure>

            <h2>The Geometry of Loss Landscapes</h2>
            <p>
                Consider a neural network with parameters θ ∈ ℝⁿ and a loss function L(θ). The loss landscape can be 
                visualized as a high-dimensional surface, where each point represents a particular configuration of the 
                network's parameters. The geometry of this surface plays a crucial role in the network's training dynamics.
            </p>

            <p>
                One of the key insights from recent research is that the loss landscape isn't as irregular as previously 
                thought. In fact, there are several geometric properties that make optimization possible:
            </p>

            <blockquote>
                "The success of neural network optimization is not a result of finding 'special' minima, but rather 
                a consequence of the geometric structure of high-dimensional spaces." — Recent findings in optimization theory
            </blockquote>

            <h3>Local Minima and Saddle Points</h3>
            <p>
                In high dimensions, the prevalence of saddle points becomes a more significant challenge than local minima. 
                The probability of encountering a local minimum decreases exponentially with the dimension, while saddle 
                points become increasingly common. This can be expressed mathematically as:
            </p>

            <div class="math">
                P(critical point is local min) ≈ 2^(-d)
            </div>

            <p>
                where d is the dimension of the parameter space. This relationship helps explain why techniques like 
                gradient descent with momentum work well in practice.
            </p>

            <div class="interactive-graph">
                <h4 class="graph-title">Interactive Loss Landscape Visualization</h4>
                <div id="loss-landscape-graph" class="graph-container"></div>
                <div class="graph-description">
                    This 3D visualization shows a simplified loss landscape. Try rotating and zooming to explore how the surface geometry affects optimization paths.
                </div>
            </div>

            <h2>Practical Implementation</h2>
            <p>
                Let's look at a simple implementation of gradient descent with momentum in Python:
            </p>

            <pre><code>import numpy as np

def gradient_descent_momentum(loss_fn, grad_fn, theta_init, learning_rate=0.01, 
                            momentum=0.9, n_iterations=1000):
    theta = theta_init
    velocity = np.zeros_like(theta)
    
    for i in range(n_iterations):
        grad = grad_fn(theta)
        velocity = momentum * velocity - learning_rate * grad
        theta = theta + velocity
        
        if i % 100 == 0:
            loss = loss_fn(theta)
            print(f"Iteration {i}, Loss: {loss:.6f}")
    
    return theta</code></pre>

            <p>
                This implementation showcases how momentum helps navigate the loss landscape more effectively by 
                accumulating gradients over time, making it less likely to get stuck in saddle points.
            </p>

            <h2>Recent Developments</h2>
            <p>
                Modern optimization techniques have built upon these geometric insights. For instance, adaptive learning 
                rate methods like Adam can be understood as implicitly adapting to the local geometry of the loss landscape. 
                These methods effectively precondition the gradient using estimates of first and second moments:
            </p>

            <div class="math">
                m_t = β₁m_{t-1} + (1-β₁)∇L(θ_t)
                v_t = β₂v_{t-1} + (1-β₂)(∇L(θ_t))²
            </div>

            <p>
                This adaptive behavior helps handle the varying scales of different parameters and the changing curvature 
                of the loss landscape during training.
            </p>

            <div class="interactive-graph">
                <h4 class="graph-title">Mathematical Functions in Optimization</h4>
                <div id="desmos-calculator" class="graph-container desmos-container"></div>
                <div class="graph-description">
                    Explore different mathematical functions commonly encountered in neural network optimization. Try modifying the parameters or adding your own functions!
                </div>
            </div>

            <h3>Future Directions</h3>
            <p>
                Current research is exploring several promising directions:
            </p>
            <ul>
                <li>Understanding the role of over-parameterization in creating more favorable geometric properties</li>
                <li>Developing optimization methods that explicitly exploit the geometry of neural network loss landscapes</li>
                <li>Investigating the connection between initialization, architecture, and the resulting loss landscape</li>
            </ul>

            <p>
                These areas of research continue to provide new insights into why deep learning works as well as it does, 
                and how we can make it work even better.
            </p>
        </div>

        <footer class="article-footer">
            <div class="article-tags">
                <span class="article-tag">Neural Networks</span>
                <span class="article-tag">Optimization</span>
                <span class="article-tag">Mathematics</span>
                <span class="article-tag">Machine Learning</span>
            </div>
            <div class="article-share">
                <a href="#" class="share-button">
                                    <svg class="x-logo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
                Share on X
                </a>
                <a href="#" class="share-button">
                    <i class="fab fa-linkedin"></i>
                    Share on LinkedIn
                </a>
                <a href="#" class="share-button">
                    <i class="fas fa-link"></i>
                    Copy Link
                </a>
            </div>
        </footer>
    </article>

    <script>
        // Initialize KaTeX rendering
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false}
                ]
            });

            // Initialize interactive graphs
            initializeLossLandscape();
            initializeDesmosCalculator();
        });

        // Initialize 3D Loss Landscape with Plotly
        function initializeLossLandscape() {
            // Generate data for a loss landscape (simplified)
            const size = 50;
            const x = [], y = [], z = [];
            
            for (let i = 0; i < size; i++) {
                x[i] = [];
                y[i] = [];
                z[i] = [];
                for (let j = 0; j < size; j++) {
                    const xVal = (i - size/2) * 0.3;
                    const yVal = (j - size/2) * 0.3;
                    
                    x[i][j] = xVal;
                    y[i][j] = yVal;
                    
                    // Create a loss landscape with multiple local minima
                    z[i][j] = Math.sin(xVal) * Math.cos(yVal) + 
                             0.3 * Math.sin(3*xVal) * Math.cos(2*yVal) + 
                             0.1 * (xVal*xVal + yVal*yVal);
                }
            }

            const data = [{
                z: z,
                x: x,
                y: y,
                type: 'surface',
                colorscale: [
                    [0, '#667eea'],
                    [0.5, '#764ba2'],
                    [1, '#f093fb']
                ],
                contours: {
                    z: {
                        show: true,
                        usecolormap: true,
                        highlightcolor: "#42f462",
                        project: {z: true}
                    }
                }
            }];

            const layout = {
                title: 'Neural Network Loss Landscape',
                autosize: true,
                scene: {
                    xaxis: {title: 'Parameter θ₁'},
                    yaxis: {title: 'Parameter θ₂'},
                    zaxis: {title: 'Loss L(θ)'},
                    camera: {
                        eye: {x: 1.2, y: 1.2, z: 0.6}
                    }
                },
                margin: {l: 0, r: 0, b: 0, t: 40}
            };

            const config = {
                responsive: true,
                displayModeBar: true,
                modeBarButtonsToRemove: ['pan2d', 'lasso2d']
            };

            Plotly.newPlot('loss-landscape-graph', data, layout, config);
        }

        // Initialize Desmos Calculator
        function initializeDesmosCalculator() {
            const elt = document.getElementById('desmos-calculator');
            const calculator = Desmos.GraphingCalculator(elt, {
                expressions: true,
                settingsMenu: true,
                zoomButtons: true,
                expressionsTopbar: true
            });

            // Add some example functions related to optimization
            calculator.setExpression({
                id: 'sigmoid',
                latex: 'f(x) = \\frac{1}{1 + e^{-x}}',
                color: '#667eea'
            });

            calculator.setExpression({
                id: 'tanh',
                latex: 'g(x) = \\tanh(x)',
                color: '#764ba2'
            });

            calculator.setExpression({
                id: 'relu',
                latex: 'h(x) = \\max(0, x)',
                color: '#f093fb'
            });

            calculator.setExpression({
                id: 'quadratic',
                latex: 'L(x) = (x-2)^2 + 1',
                color: '#42f462'
            });

            // Set the viewing window
            calculator.setMathBounds({
                left: -5,
                right: 5,
                bottom: -2,
                top: 5
            });
        }

        // Mobile menu toggle
        const hamburger = document.querySelector(".hamburger");
        const navMenu = document.querySelector(".nav-menu");

        hamburger.addEventListener("click", () => {
            hamburger.classList.toggle("active");
            navMenu.classList.toggle("active");
        });

        document.querySelectorAll(".nav-link").forEach(n => n.addEventListener("click", () => {
            hamburger.classList.remove("active");
            navMenu.classList.remove("active");
        }));

        // Copy link functionality
        document.querySelector('.share-button:last-child').addEventListener('click', function(e) {
            e.preventDefault();
            navigator.clipboard.writeText(window.location.href);
            alert('Link copied to clipboard!');
        });
    </script>
</body>
</html> 